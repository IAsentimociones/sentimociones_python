{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r')as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n"
     ]
    }
   ],
   "source": [
    "file = 'dataset1_es.txt'\n",
    "data = read_data(file)\n",
    "print(\"Number of instances: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizaci칩n y la generaci칩n de las caracter칤sticas de una oraci칩n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token, n): \n",
    "    output = []\n",
    "    for i in range(n-1, len(token)): \n",
    "        ngram = ' '.join(token[i-n+1:i+1])\n",
    "        output.append(ngram) \n",
    "    return output\n",
    "\n",
    "def create_feature(text, nrange=(1, 1)):\n",
    "    text_features = [] \n",
    "    text = text.lower() \n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    for n in range(nrange[0], nrange[1]+1): \n",
    "        text_features += ngram(text_alphanum.split(), n)    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funci칩n para almacenar las etiquetas, que se basar치n en emociones como Alegr칤a, Miedo, Ira, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(item, name): \n",
    "    #print('item: ', item)\n",
    "    #print('name: ', name)\n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)): \n",
    "        if items[idx] == 1: \n",
    "            label += name[idx] + \" \"\n",
    "    \n",
    "    return label.strip()\n",
    "\n",
    "emotions = [\"alegr칤a\", 'miedo', \"ira\", \"tristeza\", \"disgusto\", \"verg칲enza\", \"culpa\"]\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "for label, text in data:\n",
    "    y_all.append(convert_label(label, emotions))\n",
    "    X_all.append(create_feature(text, nrange=(1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separaci칩n de datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n",
    "\n",
    "def train_test(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = True)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con cuatro modelos de aprendizaje autom치tico. Se imprime resultados para la selecci칩n del mejor modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Classifier                | Training Accuracy | Test Accuracy |\n",
      "| ------------------------- | ----------------- | ------------- |\n",
      "| SVC                       |         0.9097594 |     0.4699198 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tools\\ides\\anaconda\\envs\\entorno_prueba\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LinearSVC                 |         0.9988302 |     0.5514706 |\n",
      "| RandomForestClassifier    |         0.9988302 |     0.5421123 |\n",
      "| DecisionTreeClassifier    |         0.9988302 |     0.4318182 |\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "lsvc = LinearSVC(random_state=123)\n",
    "rforest = RandomForestClassifier(random_state=123)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "clifs = [svc, lsvc, rforest, dtree]\n",
    "\n",
    "# train and test them \n",
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "for clf in clifs: \n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))\n",
    "\n",
    "#clf_name = svc.__class__.__name__\n",
    "#train_acc, test_acc = train_test(svc, X_train, X_test, y_train, y_test)\n",
    "#print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definici칩n de la etiqueta emocional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegr칤a   (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "ira       (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "tristeza  (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "miedo     (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgusto  (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "culpa     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "verg칲enza (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    }
   ],
   "source": [
    "l = [\"alegr칤a\", 'miedo', \"ira\", \"tristeza\", \"disgusto\", \"verg칲enza\", \"culpa\"]\n",
    "l.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "\n",
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definici칩n del emoji y aplicaci칩n del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegr칤a impresionante 游땍 alegr칤a\n",
      "Tengo miedo a los perros 游땸 miedo\n",
      "Mi perro muri칩 ayer 游땩 tristeza\n",
      "ya no te amo...! 游땹 verg칲enza\n",
      "alegr칤a alegr칤a muri칩 muri칩 alegr칤a alegr칤a alegr칤a 游땩 tristeza\n"
     ]
    }
   ],
   "source": [
    "emoji_dict = {\"alegr칤a\":\"游땍\", \"miedo\":\"游땸\", \"ira\":\"游\", \"tristeza\":\"游땩\", \"disgusto\":\"游뇦", \"verg칲enza\":\"游땹\", \"culpa\":\"游땹\"}\n",
    "t1 = \"alegr칤a impresionante\"\n",
    "t2 = \"Tengo miedo a los perros\"\n",
    "t3 = \"Mi perro muri칩 ayer\"\n",
    "t4 = \"ya no te amo...!\"\n",
    "t5 = 'alegr칤a alegr칤a muri칩 muri칩 alegr칤a alegr칤a alegr칤a'\n",
    "\n",
    "texts = [t1, t2, t3, t4, t5]\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    print( text,emoji_dict[prediction], prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('entorno_prueba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df928c92915a6e295095bb07de7b84624befc7d196e01c26e318bdc14196d6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
